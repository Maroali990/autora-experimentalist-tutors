{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this benchmarking challenge, you will be tasked to create an [AutoRA experimentalist](https://autoresearch.github.io/autora/experimentalist/) that efficiently samples experiments in order to advance model discovery.\n",
        "\n",
        "You can use this notebook to benchmark your experimentalist. Here, we will simulate a discovery experiment in which three different theorists are at work after each data collection cycle. You get to try out your experimentalist for two different ground truth models.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "Your goal is to optimize the data collection process in the following workflow:\n",
        "\n",
        "1. Sample 10 initial data points\n",
        "2. Fit all theorists to those data points.\n",
        "\n",
        "For 20 data points:\n",
        "3. Pick a single novel data point using your experimentalist method. Your method may or may not take into account any of the theorists' models.\n",
        "4. Add the data point to the experiment data.\n",
        "5. Fit all theorists to the experiment data\n",
        "6. Repeat steps 3-6 until 20 data points were collected\n",
        "\n",
        "This workflow can be repeated two ground-truth models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmZ1RNydtCA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking Challenge Rules\n",
        "\n",
        "- All contributing teams must publish a pip package of their experimentalist (we recommend using a pre-release) or have a working git repository that can be installed via ``!pip install git+https://github.com/musslick/autora-experimentalist-example``\n",
        "- The package name must be ``autora-experimentalist-yourexperimentalist``\n",
        "- The **experimentalist must have a sample function (see [this guide](https://autoresearch.github.io/autora/contribute/modules/experimentalist/))**, and it must be **compatible with the state logic** in this notebook.\n",
        "\n",
        "- Teams will be ranked based on the final fit to a ground-truth model. Observations will be sampled across the entire domain of the ground-truth model. The rank will be accumulated across all benchmarking challenges. The team with the best accumulated rank will win a prize at the end of the workshop.\n",
        "- The teams must provide a **brief presentation** (less than 5 minutes) of their experimentalist just before the final evaluation. You may use [this template for your slides](https://docs.google.com/presentation/d/1qCKqH9uXkQmGqDmROh1Jn4UcauALkMRhqlbAHubns2Q/edit?usp=sharing).\n",
        "\n",
        "*Hint: You may take some inspiration (or come up with a combination of) the [existing experimentalists](https://autoresearch.github.io/autora/experimentalist/).*"
      ],
      "metadata": {
        "id": "Cvka_h_k3KhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "\n",
        "- Due date: **August 30**\n",
        "- Submission: Through ``Stud.IP -> Tasks -> Experiment Sampling Challenge``\n",
        "\n",
        "The grading is independent of the outcome of the benchmarking challenge.\n",
        "\n",
        "The following points will be provided:\n",
        "- A demonstration of the theorist in the ``doc/Basic Usage.ipynb``:\n",
        "  -  2 points: Demonstrating how to use the experimentalist for sampling\n",
        "  -  8 points: Demonstrating how the expeirmentalist compares to random sampling. This should be done by simulating closed-loop discovery process with a theorist of your choice (e.g., autora-theorist-bms) on at least two ground-truth models (*Hint: You could use the benchmarking part of the notebook below as a starting point*).\n",
        "- The documentation of the experimentalist in ``doc/index.md`` must speak to the following information:\n",
        "  - 2 points: the inputs: Which inputs is your experiment sampling method considering and why?\n",
        "  - 2 points: sampling method: which sampling method are you using and why?\n",
        "- 2 points: The code contains at least two useful unit tests for the experimentalist method (either doc tests or separate tests)\n",
        "- 1 point: the contributors used issues to track bugs and work on features.\n",
        "- 1 point: the contributors used (helpful) code reviews for their PRs.\n",
        "- 1 point: Unit tests are automatically executed when a pull request is created.\n",
        "- 1 point: The documentation is hosted automatically.\n",
        "\n",
        "Finally, teams must outline the contributions of each team member in their submission on ``Stud.IP -> Tasks -> Experiment Sampling Challenge``.\n",
        "\n",
        "In total, you can obtain 20 points."
      ],
      "metadata": {
        "id": "h--sPj7T3Nqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Resources\n",
        "\n",
        "- You can learn more about how to write AutoRA experimentalists in the [Contributor Guide](https://autoresearch.github.io/autora/contribute/modules/experimentalist/).\n",
        "\n",
        "- You can learn more about how to use AutoRA in the [User Tutorial](https://autoresearch.github.io/autora/tutorials/).\n",
        "\n",
        "- If you want to learn more about AutoRA states, you can check out [this tutorial on using AutoRA states](https://colab.research.google.com/drive/1yK1OBRpPZM1NgTMV9arHlE5j8xXjsGqq?usp=sharing)."
      ],
      "metadata": {
        "id": "J4ICn4w03PdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for Benchmarking your Experimentalist"
      ],
      "metadata": {
        "id": "zowXxLUR3s8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation\n",
        "\n",
        "*Hint: You may want to add ``autora`` as a development dependency in your ``pyproject.tml``.*"
      ],
      "metadata": {
        "id": "an-QPQhcljHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install autora\n",
        "!pip install autora[all-theorists]\n",
        "!pip install autora[all-experimentalists]"
      ],
      "metadata": {
        "id": "8nzJmQwQlkh_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "dLi8_Zt-l_oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# autora state\n",
        "from autora.state import State, StandardState, on_state, estimator_on_state, Delta, VariableCollection\n",
        "\n",
        "# experiment_runner\n",
        "from autora.experiment_runner.synthetic.psychology.luce_choice_ratio import luce_choice_ratio\n",
        "from autora.experiment_runner.synthetic.psychology.exp_learning import exp_learning\n",
        "from autora.experiment_runner.synthetic.economics.expected_value_theory import expected_value_theory\n",
        "\n",
        "# experimentalist\n",
        "from autora.experimentalist.grid import grid_pool\n",
        "from autora.experimentalist.random import random_pool, random_sample\n",
        "from autora.experimentalist.falsification import falsification_sample\n",
        "from autora.experimentalist.model_disagreement import model_disagreement_sample\n",
        "from autora.experimentalist.uncertainty import uncertainty_sample\n",
        "\n",
        "# theorist\n",
        "from autora.theorist.bms import BMSRegressor\n",
        "\n",
        "# sklearn\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "\n",
        "# general\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, List\n"
      ],
      "metadata": {
        "id": "Ty6AuO0iloHs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoRA Components & State Wrappers\n",
        "\n",
        "First, we will need some theorists. Here, we will use three theorists simultaneously:\n",
        "- the Bayesian Machine Scientist\n",
        "- a polynomial theorist (from the Equation Discovery Challenge)\n",
        "- a linear regression theorist."
      ],
      "metadata": {
        "id": "VexBfX_UDjeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polynomial Theorist\n",
        "\n",
        "Below, we will use a polynomial theorist for our discovery simulation. We saw that it did quite well in the equation discovery challenge, so why not give it a try."
      ],
      "metadata": {
        "id": "xKnfmcqMDmU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "class PolynomialRegressor:\n",
        "    \"\"\"\n",
        "    This theorist fits a polynomial function to the data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, degree: int = 3):\n",
        "      self.poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "      self.model = LinearRegression()\n",
        "\n",
        "    def fit(self, x, y):\n",
        "      features = self.poly.fit_transform(x, y)\n",
        "      self.model.fit(features, y)\n",
        "      return self\n",
        "\n",
        "    def predict(self, x):\n",
        "      features = self.poly.fit_transform(x)\n",
        "      return self.model.predict(features)\n",
        "\n",
        "    def print_eqn(self):\n",
        "        # Extract the coefficients and intercept\n",
        "        coeffs = self.model.coef_\n",
        "        intercept = self.model.intercept_\n",
        "\n",
        "        # Handle multi-output case by iterating over each output's coefficients and intercept\n",
        "        if coeffs.ndim > 1:\n",
        "            for idx in range(coeffs.shape[0]):\n",
        "                equation = f\"y{idx+1} = {intercept[idx]:.3f}\"\n",
        "                feature_names = self.poly.get_feature_names_out()\n",
        "                for coef, feature in zip(coeffs[idx], feature_names):\n",
        "                    equation += f\" + ({coef:.3f}) * {feature}\"\n",
        "                print(equation)\n",
        "        else:\n",
        "            equation = f\"y = {intercept:.3f}\"\n",
        "            feature_names = self.poly.get_feature_names_out()\n",
        "            for coef, feature in zip(coeffs, feature_names):\n",
        "                equation += f\" + ({coef:.3f}) * {feature}\"\n",
        "            print(equation)\n",
        "\n"
      ],
      "metadata": {
        "id": "L3el1qBjD2K4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoRA State\n",
        "\n",
        "Next, we define our AutoRA state which acts as modifiable \"bucket\" for all the data we are going to collect during the discovery cycle. Here, we will implement a more complicated AutoRA experiment in which we have simutlaneously fit 3 models (from 3 different theorists) and we want to keep track of all of them."
      ],
      "metadata": {
        "id": "s6lhZO-SI8LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SET UP STATE\n",
        "# Here, we use a non-standard State to be able to use a multiple models\n",
        "@dataclass(frozen=True)\n",
        "class CustomState(State):\n",
        "    variables: Optional[VariableCollection] = field(\n",
        "        default=None, metadata={\"delta\": \"replace\"}\n",
        "    )\n",
        "    conditions: Optional[pd.DataFrame] = field(\n",
        "        default=None, metadata={\"delta\": \"replace\", \"converter\": pd.DataFrame}\n",
        "    )\n",
        "    experiment_data: Optional[pd.DataFrame] = field(\n",
        "        default=None, metadata={\"delta\": \"extend\", \"converter\": pd.DataFrame}\n",
        "    )\n",
        "    models_bms: List[BaseEstimator] = field(\n",
        "        default_factory=list,\n",
        "        metadata={\"delta\": \"extend\"},\n",
        "    )\n",
        "    models_lr: List[BaseEstimator] = field(\n",
        "        default_factory=list,\n",
        "        metadata={\"delta\": \"extend\"},\n",
        "    )\n",
        "    models_polyr: List[BaseEstimator] = field(\n",
        "        default_factory=list,\n",
        "        metadata={\"delta\": \"extend\"},\n",
        "    )"
      ],
      "metadata": {
        "id": "rUlJzPVbJRg_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoRA State Wrappers\n",
        "\n",
        "Next, we need to define a bunch of wrappers. These wrappers will make it easy to operate on the state. They specify which things are being pulled from the state and which things are being stored."
      ],
      "metadata": {
        "id": "Hl65zUC-I2vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Theorist Wrapper"
      ],
      "metadata": {
        "id": "_ahabyf9J5RF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# state wrapper for all theorists\n",
        "@on_state()\n",
        "def theorists_on_state(experiment_data, variables, bms_epochs):\n",
        "\n",
        "  # extract conditions X and observations y from experiment data\n",
        "  ivs = [iv.name for iv in variables.independent_variables]\n",
        "  dvs = [dv.name for dv in variables.dependent_variables]\n",
        "  X = experiment_data[ivs]\n",
        "  y = experiment_data[dvs]\n",
        "\n",
        "  # initialize and fit theorists\n",
        "  theorist_bms = BMSRegressor(epochs=bms_epochs)\n",
        "  theorist_polyr = PolynomialRegressor()\n",
        "  theorist_lr = linear_model.LinearRegression()\n",
        "\n",
        "  return Delta(models_bms = [theorist_bms.fit(X, y)],\n",
        "               models_lr=[theorist_lr.fit(X, y)],\n",
        "               models_polyr=[theorist_polyr.fit(X, y)])"
      ],
      "metadata": {
        "id": "07NSganHJ7Pf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentalist Wrappers"
      ],
      "metadata": {
        "id": "7n4buGk3LEmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# state wrapper for grid pooler experimentalist (generates a grid of experiment conditions)\n",
        "@on_state()\n",
        "def grid_pool_on_state(variables):\n",
        "  return Delta(conditions=grid_pool(variables))\n",
        "\n",
        "# state wrapper for random pooler experimentalist (generates a pool of experiment conditions)\n",
        "@on_state()\n",
        "def random_pool_on_state(variables, num_samples, random_state=None):\n",
        "  return Delta(conditions=random_pool(variables, num_samples, random_state))\n",
        "\n",
        "# state wrapper for random experimentalist (samples experiment conditions from a set of conditions)\n",
        "@on_state()\n",
        "def random_sample_on_state(conditions, all_conditions, num_samples, random_state=None):\n",
        "  return Delta(conditions=random_sample(all_conditions, num_samples, random_state))\n",
        "\n",
        "# **** STATE WRAPPER FOR YOUR EXPERIMENTALIST ***\n",
        "@on_state()\n",
        "def custom_sample_on_state(experiment_data,\n",
        "                           models_bms,\n",
        "                           models_lr,\n",
        "                           models_polyr,\n",
        "                           all_conditions,\n",
        "                           num_samples=1,\n",
        "                           random_state=None):\n",
        "\n",
        "  # this is just an example where we integrate the model diagreement sampler\n",
        "  # into the wrapper\n",
        "  conditions = model_disagreement_sample(\n",
        "          all_conditions,\n",
        "          models = [models_bms[-1], models_lr[-1]],\n",
        "          num_samples = num_samples\n",
        "      )\n",
        "\n",
        "  return Delta(conditions=conditions)"
      ],
      "metadata": {
        "id": "_uw7z74IJtGx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment Runner Wrapper"
      ],
      "metadata": {
        "id": "9DyqbEH2LB-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# state wrapper for synthetic experiment runner\n",
        "@on_state()\n",
        "def run_experiment_on_state(conditions, experiment_runner):\n",
        "  data = experiment_runner.run(conditions=conditions, added_noise=0.0)\n",
        "  return Delta(experiment_data=data)"
      ],
      "metadata": {
        "id": "fyUlh7vBJQwk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation Functions\n",
        "\n",
        "First, we will need a function that we can use to evaluate the goodness of our theorists. We will use the one below (no need to parse it)."
      ],
      "metadata": {
        "id": "pwlTublQiWMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the following function is used to compute the model performance\n",
        "# on the validation set in terms of mean squared error\n",
        "def get_validation_MSE(validation_experiment_data, working_state):\n",
        "    ivs = [iv.name for iv in validation_experiment_data.variables.independent_variables]\n",
        "    dvs = [dv.name for dv in validation_experiment_data.variables.dependent_variables]\n",
        "    X = validation_experiment_data.experiment_data[ivs]\n",
        "    y = validation_experiment_data.experiment_data[dvs]\n",
        "\n",
        "    y_pred_bms = working_state.models_bms[-1].predict(X)\n",
        "    y_pred_lr = working_state.models_lr[-1].predict(X)\n",
        "    y_pred_polyr = working_state.models_polyr[-1].predict(X)\n",
        "\n",
        "    MSE_bms = ((y - y_pred_bms)**2).mean()[0]\n",
        "    MSE_lr = ((y - y_pred_lr)**2).mean()[0]\n",
        "    MSE_polyr = ((y - y_pred_polyr)**2).mean()[0]\n",
        "\n",
        "    min_MSE = min(MSE_bms, MSE_lr, MSE_polyr)\n",
        "\n",
        "    return min_MSE"
      ],
      "metadata": {
        "id": "uHuIbsSbN0Ng"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the following function for benchmarking our model for any given experiment runner. Have a closer look at the script below.\n",
        "\n",
        "It uses four different AutoRA states:\n",
        "- ``validation_conditions`` and ``validation_experiment_data``: These states contains our validation sets, sampled across the entire domain of the ground truth. It is used for tracking the validation MSE of all theorists.\n",
        "\n",
        "- ``initial_state``: This state is used to initialize the discovery process. Both the random experimentalist (operating on the ``benchmark_state``) and your custom experimentalist (operating on the ``working_state`` will use the same initial state.)\n",
        "\n",
        "- ``benchmark_state``: This state is used for a discovery process with random sampling.\n",
        "\n",
        "- ``working_state``: This state is used for a discovery process with your custom experimentalist."
      ],
      "metadata": {
        "id": "k8mSIAfmN9Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner, sim=0):\n",
        "\n",
        "  # VALIDATION STATE\n",
        "  # at every step of our discovery process, we will evaluate the performance\n",
        "  # of the theorist against the ground truth. Here, we will define the ground\n",
        "  # truth as a grid of data points sampled across the domain of the experimental\n",
        "  # design space. We will store this validation set in a separate validation states\n",
        "\n",
        "  # create AutoRA state for validation purposes\n",
        "  validation_conditions = CustomState(variables=experiment_runner.variables)\n",
        "  validation_experiment_data = CustomState(variables=experiment_runner.variables)\n",
        "\n",
        "  # our validation set will be consist of a grid of experiment conditons\n",
        "  # across the entire experimental design domain\n",
        "  validation_conditions = grid_pool_on_state(validation_conditions)\n",
        "  validation_experiment_data = grid_pool_on_state(validation_experiment_data)\n",
        "  validation_experiment_data = run_experiment_on_state(validation_experiment_data, experiment_runner=experiment_runner)\n",
        "\n",
        "\n",
        "  benchmark_MSE_log = list()\n",
        "  working_MSE_log = list()\n",
        "\n",
        "  for sim in range(num_discovery_simulations):\n",
        "\n",
        "    # INITIAL STATE\n",
        "    # We begin our discovery experiment with randomly sampled data set for 10\n",
        "    # conditions. We will use the same state for each experimentalist method.\n",
        "\n",
        "    # create initial AutoRA state which we will use for our discovery expeirments\n",
        "    initial_state = CustomState(variables=experiment_runner.variables)\n",
        "\n",
        "    # we will initiate our discovery process with 10 randomly sampled experiment conditions\n",
        "    initial_state = random_pool_on_state(initial_state,\n",
        "                                        num_samples=num_initial_conditions,\n",
        "                                        random_state = sim)\n",
        "\n",
        "    # we obtain the corresponding experiment data\n",
        "    initial_state = run_experiment_on_state(initial_state, experiment_runner=experiment_runner)\n",
        "\n",
        "    # initialize benchmark state for random experimentalist\n",
        "    benchmark_state = CustomState(**initial_state.__dict__)\n",
        "\n",
        "    # initialize working state for your custom experimentalist\n",
        "    working_state = CustomState(**initial_state.__dict__)\n",
        "\n",
        "    # for each discovery cycle\n",
        "    for cycle in range(num_cycles):\n",
        "\n",
        "      print(\"SIMULATION \" + str(sim)  + \" / DISCOVERY CYCLE \" + str(cycle))\n",
        "\n",
        "      # first, we fit a model to the data\n",
        "      print(\"Fitting models on benchmark state...\")\n",
        "      benchmark_state = theorists_on_state(benchmark_state, bms_epochs=bms_epochs)\n",
        "      print(\"Fitting models on working state...\")\n",
        "      working_state = theorists_on_state(working_state, bms_epochs=bms_epochs)\n",
        "\n",
        "      # now we can determine how well the models do on the validation set\n",
        "      benchmark_MSE = get_validation_MSE(validation_experiment_data, benchmark_state)\n",
        "      benchmark_MSE_log.append(benchmark_MSE)\n",
        "\n",
        "      working_MSE = get_validation_MSE(validation_experiment_data, working_state)\n",
        "      working_MSE_log.append(working_MSE)\n",
        "\n",
        "      # then we determine the next experiment condition\n",
        "      print(\"Sampling new experiment conditions...\")\n",
        "      benchmark_state = random_sample_on_state(benchmark_state,\n",
        "                                               all_conditions=validation_conditions.conditions,\n",
        "                                               num_samples=num_conditions_per_cycle)\n",
        "      working_state = custom_sample_on_state(working_state,\n",
        "                                             all_conditions=validation_conditions.conditions,\n",
        "                                            num_samples=num_conditions_per_cycle)\n",
        "\n",
        "      print(\"Obtaining observations...\")\n",
        "      # we obtain the corresponding experiment data\n",
        "      benchmark_state = run_experiment_on_state(benchmark_state, experiment_runner=experiment_runner)\n",
        "      working_state = run_experiment_on_state(working_state, experiment_runner=experiment_runner)\n",
        "\n",
        "    return benchmark_MSE_log, working_MSE_log, benchmark_state, working_state"
      ],
      "metadata": {
        "id": "-2n53aEYLhEF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking Script"
      ],
      "metadata": {
        "id": "3B5mO66GMb3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first set some meta-parameters."
      ],
      "metadata": {
        "id": "mqu8m-hjfXVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# meta parameters\n",
        "\n",
        "# DO NOT CHANGE THESE PARAMETERS\n",
        "num_cycles = 20\n",
        "num_conditions_per_cycle = 1\n",
        "num_initial_conditions = 1\n",
        "\n",
        "# YOU MAY CHANGE THESE PARAMETERS\n",
        "num_discovery_simulations = 10\n",
        "bms_epochs = 100 # Note, to speed things up, you can set bms_epochs = 10 or even bms_epochs = 1 (this will lead to poor performance of the BMS regressor but the other two theorists will still fit)"
      ],
      "metadata": {
        "id": "40rWpRCKfcGL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Run\n",
        "\n",
        "We recommend that you probe your experimentalist function for a single run. Once you are confident that your experimentalist works, we recommend running repeating the simulation experiment for at least iterations (``num_discovery_simulations``).\n",
        "\n",
        "How do your results look like for other ground truths, such as\n",
        "- ``luce_choice_ratio()`` or\n",
        "- ``expected_value_theory()`` ?"
      ],
      "metadata": {
        "id": "s5s2_nSTMnHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting experiment runner and theorist\n",
        "experiment_runner = exp_learning()\n",
        "\n",
        "# run simulation\n",
        "benchmark_MSE_log, working_MSE_log, benchmark_state, working_state = run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqsuMqTd1OaY",
        "outputId": "b568853d-a4a7-4ffa-b2b1-97a509315ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIMULATION 0 / DISCOVERY CYCLE 0\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:23<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:15<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 1\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 2\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 3\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 4\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:12<00:00,  8.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 5\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 6\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 11.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 7\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 8\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 9\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 10\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 11\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  8.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling new experiment conditions...\n",
            "Obtaining observations...\n",
            "SIMULATION 0 / DISCOVERY CYCLE 12\n",
            "Fitting models on benchmark state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:11<00:00,  9.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting models on working state...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [00:01<00:11,  8.06it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now plot the results for a single discovery run."
      ],
      "metadata": {
        "id": "DxXTCLDzfjLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets plot the benchmark_MSE_log and the workign_MSE_log\n",
        "plt.plot(benchmark_MSE_log, label='benchmark_MSE_log')\n",
        "plt.plot(working_MSE_log, label='working_MSE_log')\n",
        "plt.xlabel('Sampled Data Points')\n",
        "plt.ylabel('MSE on Validation Set')\n",
        "plt.title('Single Discovery Simulation')\n",
        "plt.legend()\n",
        "\n",
        "# we can also investigate the final state more closely\n",
        "# for example, these are all the experimental data collected\n",
        "# under random sampling:\n",
        "print(benchmark_state.experiment_data)\n",
        "# and for your custom experimentalist\n",
        "print(working_state.experiment_data)"
      ],
      "metadata": {
        "id": "0HfiASzDfiRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging Across Multiple Runs\n",
        "\n",
        "To become more confident in your experimentalist, you may want to repeat the discovery process N times..."
      ],
      "metadata": {
        "id": "H8Z7iU9pgBWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_MSE_plot_data = np.zeros([num_discovery_simulations, num_cycles])\n",
        "working_MSE_plot_data = np.zeros([num_discovery_simulations, num_cycles])\n",
        "\n",
        "for sim in range(num_discovery_simulations):\n",
        "  benchmark_MSE_log, working_MSE_log, benchmark_state, working_state = run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner, sim)\n",
        "\n",
        "  benchmark_MSE_plot_data[sim, :] = benchmark_MSE_log\n",
        "  working_MSE_plot_data[sim, :] = working_MSE_log"
      ],
      "metadata": {
        "id": "OwL3zbg7hQNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the data with standard error\n",
        "plt.errorbar(np.arange(num_cycles), np.mean(benchmark_MSE_plot_data, axis=0), yerr=np.std(benchmark_MSE_plot_data, axis=0), label='benchmark_MSE_log')\n",
        "plt.errorbar(np.arange(num_cycles), np.mean(working_MSE_plot_data, axis=0), yerr=np.std(working_MSE_plot_data, axis=0), label='working_MSE_log')\n",
        "plt.xlabel('Sampled Data Points')\n",
        "plt.ylabel('MSE on Validation Set')\n",
        "plt.title('Averaged Discovery Simulations')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "5eL0nqtXhrAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ground Truth Model Descriptions"
      ],
      "metadata": {
        "id": "RPPjmh_niqzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weber-Fechner-Law\n",
        "\n",
        "The Weber-Fechner law quantifies the minimum change in a stimulus required to be noticeable. Similar to Steven's power law, the greater the intensity of a stimulus, the larger the change needed to be perceivable. This relationship is hypothesized to be proportional to the logarithm of the ratio between the two stimuli:\n",
        "\n",
        "$\\text{perceived intensity} = \\log\\left(\\dfrac{S_1}{S_2}\\right)$\n",
        "\n",
        "\n",
        "where $S_1$ ($range: [0.01, 5.00]$) is the intensity of a physical stimulus (e.g., the luminosity of a lamp), $S_2$ ($range: [0.01, 5.00]$ ) is a reference stimulus (e.g., the luminosity of a background light), and $y$ is the perceived stimulus intensity (e.g. the perception of the lamp's luminosity)."
      ],
      "metadata": {
        "id": "HI7aHUNOZpbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expected Utility Model with Two Choice Options\n",
        "\n",
        "The expected utility model evaluates decision-making under uncertainty, quantifying the expected value of different choices based on their potential outcomes and associated probabilities. The model assumes that individuals aim to maximize their expected utility when faced with two options. Each option has a specific value and probability, influenced by a certain level of noise.\n",
        "\n",
        "For two choice options, the expected value of each option is calculated as follows:\n",
        "\n",
        "$$\n",
        "E_A = V_A \\times P_A\n",
        "$$\n",
        "\n",
        "$$\n",
        "E_B = V_B \\times P_B\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $V_A$ and $V_B$ represent the values of options A and B respectively.\n",
        "- $P_A$ and $P_B$ represent the probabilities associated with these options.\n",
        "\n",
        "The probability of choosing option A $P_{\\text{choose}_A}$ is then determined using the softmax function, which considers the expected values of both options and a choice temperature parameter that influences the sensitivity to differences in expected values:\n",
        "\n",
        "$$\n",
        "P_{\\text{choose}_A} = \\frac{\\exp(E_A / \\beta)}{\\exp(E_A / \\beta) + \\exp(E_B / \\beta)}\n",
        "$$\n",
        "\n",
        "In this model:\n",
        "- $\\beta$ controls the degree of randomness in the choice, with higher values leading to more exploration and lower values leading to more deterministic choices based on the expected values.\n",
        "- The softmax function ensures that the probabilities sum to 1, providing a normalized measure of the likelihood of choosing each option.\n",
        "\n",
        "This model captures the influence of value, probability, and noise on decision-making, reflecting the complexity and variability of human choices under uncertainty.\n",
        "\n"
      ],
      "metadata": {
        "id": "iZGn2XzoaUF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shepard-Luce Choice Rule\n",
        "\n",
        "The Shepard-Luce choice rule, as adapted in Logan (2001),  posits that the likelihood of an individual assigning a target object, represented as $x$ , to a specific response category, represented as $i$, is proportional to their psychological similarity $\\eta_i(x)$. Here, we considered a version of the model that computes the probability of assigning the target object $x_1$ to one of two response categories, given a distractor object $x_2$:\n",
        "\n",
        "$y = p(``x_1 \\text{ is perceived as category 1''}) =\n",
        " \\frac{\\eta_1(x_1) \\cdot \\alpha}{\\eta_1(x_1) \\cdot \\alpha + \\eta_2(x_1) \\cdot \\alpha + \\eta_1(x_2) \\cdot (1 - \\alpha) + \\eta_2(x_2) \\cdot (1 - \\alpha)}$\n",
        "\n",
        "where $\\alpha = 0.8$ is an attentional bias toward processing the target object $x_1$, and variables $\\eta_i(x_j)$ ($range: [0.125, 10.00]$) are the psychological similarity between object $x_j$ and category $i$."
      ],
      "metadata": {
        "id": "i0E46LLlixsD"
      }
    }
  ]
}